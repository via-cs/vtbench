{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29f28ff8-2840-4484-8174-dd2d7b6993b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 samples from ECG/ECG_TRAIN.ts\n",
      "Loaded 100 samples from ECG/ECG_TEST.ts\n",
      "Fold 1/5\n",
      "Epoch [1/100], Loss: 1.3201, Training Accuracy: 55.62%\n",
      "Test Accuracy after Epoch 1: 65.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vmadhuu\\AppData\\Local\\anaconda3\\envs\\tscproj\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100], Loss: 0.5763, Training Accuracy: 74.38%\n",
      "Test Accuracy after Epoch 2: 65.00%\n",
      "Epoch [3/100], Loss: 0.6246, Training Accuracy: 66.88%\n",
      "Test Accuracy after Epoch 3: 70.00%\n",
      "Epoch [4/100], Loss: 0.5800, Training Accuracy: 70.00%\n",
      "Test Accuracy after Epoch 4: 77.50%\n",
      "Epoch [5/100], Loss: 0.6633, Training Accuracy: 65.00%\n",
      "Test Accuracy after Epoch 5: 65.00%\n",
      "Epoch [6/100], Loss: 0.7310, Training Accuracy: 68.12%\n",
      "Test Accuracy after Epoch 6: 72.50%\n",
      "Epoch [7/100], Loss: 0.6135, Training Accuracy: 71.25%\n",
      "Test Accuracy after Epoch 7: 87.50%\n",
      "Epoch [8/100], Loss: 0.5367, Training Accuracy: 75.62%\n",
      "Test Accuracy after Epoch 8: 75.00%\n",
      "Epoch [9/100], Loss: 0.5831, Training Accuracy: 71.88%\n",
      "Test Accuracy after Epoch 9: 85.00%\n",
      "Epoch [10/100], Loss: 0.5951, Training Accuracy: 76.25%\n",
      "Test Accuracy after Epoch 10: 65.00%\n",
      "Epoch [11/100], Loss: 0.4989, Training Accuracy: 80.00%\n",
      "Test Accuracy after Epoch 11: 85.00%\n",
      "Epoch [12/100], Loss: 0.5738, Training Accuracy: 71.88%\n",
      "Test Accuracy after Epoch 12: 82.50%\n",
      "Epoch [13/100], Loss: 0.5248, Training Accuracy: 78.12%\n",
      "Test Accuracy after Epoch 13: 82.50%\n",
      "Epoch [14/100], Loss: 0.5009, Training Accuracy: 76.88%\n",
      "Test Accuracy after Epoch 14: 77.50%\n",
      "Epoch [15/100], Loss: 0.4357, Training Accuracy: 78.75%\n",
      "Test Accuracy after Epoch 15: 77.50%\n",
      "Epoch [16/100], Loss: 0.4472, Training Accuracy: 76.25%\n",
      "Test Accuracy after Epoch 16: 82.50%\n",
      "Epoch [17/100], Loss: 0.4071, Training Accuracy: 80.00%\n",
      "Test Accuracy after Epoch 17: 85.00%\n",
      "Early stopping at epoch 17\n",
      "Best Test Accuracy for fold 1: 87.50%\n",
      "Fold 2/5\n",
      "Epoch [1/100], Loss: 1.2222, Training Accuracy: 53.75%\n",
      "Test Accuracy after Epoch 1: 60.00%\n",
      "Epoch [2/100], Loss: 0.6038, Training Accuracy: 65.62%\n",
      "Test Accuracy after Epoch 2: 60.00%\n",
      "Epoch [3/100], Loss: 0.6127, Training Accuracy: 67.50%\n",
      "Test Accuracy after Epoch 3: 62.50%\n",
      "Epoch [4/100], Loss: 0.6342, Training Accuracy: 72.50%\n",
      "Test Accuracy after Epoch 4: 50.00%\n",
      "Epoch [5/100], Loss: 0.5821, Training Accuracy: 73.75%\n",
      "Test Accuracy after Epoch 5: 62.50%\n",
      "Epoch [6/100], Loss: 0.5785, Training Accuracy: 73.75%\n",
      "Test Accuracy after Epoch 6: 70.00%\n",
      "Epoch [7/100], Loss: 0.5068, Training Accuracy: 75.00%\n",
      "Test Accuracy after Epoch 7: 70.00%\n",
      "Epoch [8/100], Loss: 0.4673, Training Accuracy: 78.12%\n",
      "Test Accuracy after Epoch 8: 72.50%\n",
      "Epoch [9/100], Loss: 0.4840, Training Accuracy: 78.12%\n",
      "Test Accuracy after Epoch 9: 57.50%\n",
      "Epoch [10/100], Loss: 0.4810, Training Accuracy: 78.75%\n",
      "Test Accuracy after Epoch 10: 70.00%\n",
      "Epoch [11/100], Loss: 0.4143, Training Accuracy: 81.25%\n",
      "Test Accuracy after Epoch 11: 70.00%\n",
      "Epoch [12/100], Loss: 0.4141, Training Accuracy: 81.25%\n",
      "Test Accuracy after Epoch 12: 65.00%\n",
      "Epoch [13/100], Loss: 0.3862, Training Accuracy: 86.25%\n",
      "Test Accuracy after Epoch 13: 65.00%\n",
      "Epoch [14/100], Loss: 0.3605, Training Accuracy: 84.38%\n",
      "Test Accuracy after Epoch 14: 65.00%\n",
      "Epoch [15/100], Loss: 0.4547, Training Accuracy: 80.00%\n",
      "Test Accuracy after Epoch 15: 72.50%\n",
      "Epoch [16/100], Loss: 0.3914, Training Accuracy: 84.38%\n",
      "Test Accuracy after Epoch 16: 72.50%\n",
      "Epoch [17/100], Loss: 0.3885, Training Accuracy: 83.75%\n",
      "Test Accuracy after Epoch 17: 72.50%\n",
      "Epoch [18/100], Loss: 0.3944, Training Accuracy: 80.62%\n",
      "Test Accuracy after Epoch 18: 65.00%\n",
      "Early stopping at epoch 18\n",
      "Best Test Accuracy for fold 2: 72.50%\n",
      "Fold 3/5\n",
      "Epoch [1/100], Loss: 1.6813, Training Accuracy: 45.00%\n",
      "Test Accuracy after Epoch 1: 32.50%\n",
      "Epoch [2/100], Loss: 0.8502, Training Accuracy: 56.25%\n",
      "Test Accuracy after Epoch 2: 67.50%\n",
      "Epoch [3/100], Loss: 0.7954, Training Accuracy: 56.25%\n",
      "Test Accuracy after Epoch 3: 67.50%\n",
      "Epoch [4/100], Loss: 0.6886, Training Accuracy: 65.00%\n",
      "Test Accuracy after Epoch 4: 55.00%\n",
      "Epoch [5/100], Loss: 0.6633, Training Accuracy: 70.62%\n",
      "Test Accuracy after Epoch 5: 72.50%\n",
      "Epoch [6/100], Loss: 0.6201, Training Accuracy: 68.75%\n",
      "Test Accuracy after Epoch 6: 85.00%\n",
      "Epoch [7/100], Loss: 0.5701, Training Accuracy: 70.62%\n",
      "Test Accuracy after Epoch 7: 72.50%\n",
      "Epoch [8/100], Loss: 0.5550, Training Accuracy: 70.00%\n",
      "Test Accuracy after Epoch 8: 80.00%\n",
      "Epoch [9/100], Loss: 0.5564, Training Accuracy: 76.88%\n",
      "Test Accuracy after Epoch 9: 77.50%\n",
      "Epoch [10/100], Loss: 0.5531, Training Accuracy: 75.00%\n",
      "Test Accuracy after Epoch 10: 72.50%\n",
      "Epoch [11/100], Loss: 0.5923, Training Accuracy: 69.38%\n",
      "Test Accuracy after Epoch 11: 75.00%\n",
      "Epoch [12/100], Loss: 0.5658, Training Accuracy: 72.50%\n",
      "Test Accuracy after Epoch 12: 72.50%\n",
      "Epoch [13/100], Loss: 0.4946, Training Accuracy: 75.62%\n",
      "Test Accuracy after Epoch 13: 80.00%\n",
      "Epoch [14/100], Loss: 0.5226, Training Accuracy: 75.62%\n",
      "Test Accuracy after Epoch 14: 77.50%\n",
      "Epoch [15/100], Loss: 0.6173, Training Accuracy: 71.88%\n",
      "Test Accuracy after Epoch 15: 67.50%\n",
      "Epoch [16/100], Loss: 0.5616, Training Accuracy: 71.25%\n",
      "Test Accuracy after Epoch 16: 75.00%\n",
      "Early stopping at epoch 16\n",
      "Best Test Accuracy for fold 3: 85.00%\n",
      "Fold 4/5\n",
      "Epoch [1/100], Loss: 1.4575, Training Accuracy: 48.75%\n",
      "Test Accuracy after Epoch 1: 75.00%\n",
      "Epoch [2/100], Loss: 0.6959, Training Accuracy: 58.12%\n",
      "Test Accuracy after Epoch 2: 75.00%\n",
      "Epoch [3/100], Loss: 0.6012, Training Accuracy: 66.88%\n",
      "Test Accuracy after Epoch 3: 45.00%\n",
      "Epoch [4/100], Loss: 0.6412, Training Accuracy: 69.38%\n",
      "Test Accuracy after Epoch 4: 92.50%\n",
      "Epoch [5/100], Loss: 0.6292, Training Accuracy: 73.12%\n",
      "Test Accuracy after Epoch 5: 77.50%\n",
      "Epoch [6/100], Loss: 0.6608, Training Accuracy: 68.12%\n",
      "Test Accuracy after Epoch 6: 82.50%\n",
      "Epoch [7/100], Loss: 0.5316, Training Accuracy: 73.12%\n",
      "Test Accuracy after Epoch 7: 82.50%\n",
      "Epoch [8/100], Loss: 0.5983, Training Accuracy: 71.25%\n",
      "Test Accuracy after Epoch 8: 75.00%\n",
      "Epoch [9/100], Loss: 0.5991, Training Accuracy: 69.38%\n",
      "Test Accuracy after Epoch 9: 82.50%\n",
      "Epoch [10/100], Loss: 0.6081, Training Accuracy: 68.75%\n",
      "Test Accuracy after Epoch 10: 75.00%\n",
      "Epoch [11/100], Loss: 0.5693, Training Accuracy: 69.38%\n",
      "Test Accuracy after Epoch 11: 52.50%\n",
      "Epoch [12/100], Loss: 0.6037, Training Accuracy: 71.88%\n",
      "Test Accuracy after Epoch 12: 90.00%\n",
      "Epoch [13/100], Loss: 0.5446, Training Accuracy: 72.50%\n",
      "Test Accuracy after Epoch 13: 77.50%\n",
      "Epoch [14/100], Loss: 0.6271, Training Accuracy: 65.00%\n",
      "Test Accuracy after Epoch 14: 72.50%\n",
      "Early stopping at epoch 14\n",
      "Best Test Accuracy for fold 4: 92.50%\n",
      "Fold 5/5\n",
      "Epoch [1/100], Loss: 1.3862, Training Accuracy: 50.62%\n",
      "Test Accuracy after Epoch 1: 65.00%\n",
      "Epoch [2/100], Loss: 0.7108, Training Accuracy: 58.75%\n",
      "Test Accuracy after Epoch 2: 65.00%\n",
      "Epoch [3/100], Loss: 0.6251, Training Accuracy: 67.50%\n",
      "Test Accuracy after Epoch 3: 57.50%\n",
      "Epoch [4/100], Loss: 0.6285, Training Accuracy: 67.50%\n",
      "Test Accuracy after Epoch 4: 67.50%\n",
      "Epoch [5/100], Loss: 0.6584, Training Accuracy: 65.62%\n",
      "Test Accuracy after Epoch 5: 75.00%\n",
      "Epoch [6/100], Loss: 0.5671, Training Accuracy: 73.75%\n",
      "Test Accuracy after Epoch 6: 72.50%\n",
      "Epoch [7/100], Loss: 0.5620, Training Accuracy: 73.12%\n",
      "Test Accuracy after Epoch 7: 75.00%\n",
      "Epoch [8/100], Loss: 0.6041, Training Accuracy: 68.75%\n",
      "Test Accuracy after Epoch 8: 60.00%\n",
      "Epoch [9/100], Loss: 0.5809, Training Accuracy: 69.38%\n",
      "Test Accuracy after Epoch 9: 67.50%\n",
      "Epoch [10/100], Loss: 0.6006, Training Accuracy: 69.38%\n",
      "Test Accuracy after Epoch 10: 72.50%\n",
      "Epoch [11/100], Loss: 0.5510, Training Accuracy: 77.50%\n",
      "Test Accuracy after Epoch 11: 72.50%\n",
      "Epoch [12/100], Loss: 0.5864, Training Accuracy: 69.38%\n",
      "Test Accuracy after Epoch 12: 70.00%\n",
      "Epoch [13/100], Loss: 0.5716, Training Accuracy: 73.75%\n",
      "Test Accuracy after Epoch 13: 70.00%\n",
      "Epoch [14/100], Loss: 0.5635, Training Accuracy: 73.75%\n",
      "Test Accuracy after Epoch 14: 72.50%\n",
      "Epoch [15/100], Loss: 0.4648, Training Accuracy: 77.50%\n",
      "Test Accuracy after Epoch 15: 62.50%\n",
      "Early stopping at epoch 15\n",
      "Best Test Accuracy for fold 5: 75.00%\n",
      "Mean Test Accuracy: 82.50%\n",
      "Standard Deviation of Test Accuracy: 7.58%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "from torchvision import transforms\n",
    "from chart_utils import TimeSeriesImageDataset, accuracy_fn\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Function to read UCR dataset\n",
    "def read_ucr(filename):\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(',')\n",
    "            if len(parts) < 2:\n",
    "                continue\n",
    "            features = [float(f) for f in parts[:-1]]\n",
    "            label = int(parts[-1].split(':')[-1])\n",
    "            data.append(features)\n",
    "            labels.append(label)\n",
    "    \n",
    "    print(f\"Loaded {len(data)} samples from {filename}\")\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "# File paths (adjust these paths as necessary)\n",
    "train_file = 'ECG/ECG_TRAIN.ts'\n",
    "test_file = 'ECG/ECG_TEST.ts'\n",
    "\n",
    "# Load dataset\n",
    "x_train, y_train = read_ucr(train_file)\n",
    "x_test, y_test = read_ucr(test_file)\n",
    "\n",
    "# Normalize labels to be within range [0, num_classes-1]\n",
    "unique_labels = np.unique(y_train)\n",
    "label_map = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "y_train = np.array([label_map[label] for label in y_train])\n",
    "y_test = np.array([label_map[label] for label in y_test])\n",
    "\n",
    "nb_classes = len(unique_labels)\n",
    "\n",
    "# Normalize features\n",
    "x_train_mean = x_train.mean()\n",
    "x_train_std = x_train.std()\n",
    "x_train = (x_train - x_train_mean) / x_train_std\n",
    "x_test = (x_test - x_train_mean) / x_train_std\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(x_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Combine train and test data for K-Fold Cross-Validation\n",
    "X = torch.cat((X_train, X_test))\n",
    "y = torch.cat((y_train, y_test))\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "k_folds = 5\n",
    "kf = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "# Define a simpler CNN Model\n",
    "class Simple2DCNN(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(Simple1DCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 16, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(16 * 32 * 32, 64)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.ReLU()(self.bn1(self.conv1(x))))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "# Data Augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # Resize to a smaller size for simpler model\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2)\n",
    "])\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
    "    print(f'Fold {fold+1}/{k_folds}')\n",
    "    \n",
    "    # Create data loaders for the current fold\n",
    "    train_data, test_data = X[train_idx], X[test_idx]\n",
    "    train_labels, test_labels = y[train_idx], y[test_idx]\n",
    "    \n",
    "    train_dataset = TimeSeriesImageDataset(train_data.numpy(), train_labels.numpy(), transform)\n",
    "    test_dataset = TimeSeriesImageDataset(test_data.numpy(), test_labels.numpy(), transform)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    # Initialize the model, criterion, optimizer, and scheduler\n",
    "    model = Simple1DCNN(6, nb_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=0.01)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n",
    "    \n",
    "    num_epochs = 100\n",
    "    best_test_accuracy = 0\n",
    "    patience = 10\n",
    "    trigger_times = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images_area, images_bar, labels in train_loader:\n",
    "            images_area, images_bar, labels = images_area.to(device), images_bar.to(device), labels.to(device)\n",
    "            \n",
    "            # Combine area and bar charts along the channel dimension\n",
    "            combined_images = torch.cat((images_area, images_bar), dim=1)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(combined_images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_accuracy = 100 * correct / total\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Training Accuracy: {epoch_accuracy:.2f}%')\n",
    "\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images_area, images_bar, labels in test_loader:\n",
    "                images_area, images_bar, labels = images_area.to(device), images_bar.to(device), labels.to(device)\n",
    "                \n",
    "                # Combine area and bar charts along the channel dimension\n",
    "                combined_images = torch.cat((images_area, images_bar), dim=1)\n",
    "                \n",
    "                outputs = model(combined_images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        test_accuracy = 100 * correct / total\n",
    "        print(f'Test Accuracy after Epoch {epoch+1}: {test_accuracy:.2f}%')\n",
    "        scheduler.step(epoch_loss)\n",
    "\n",
    "        if test_accuracy > best_test_accuracy:\n",
    "            best_test_accuracy = test_accuracy\n",
    "            trigger_times = 0\n",
    "        else:\n",
    "            trigger_times += 1\n",
    "            if trigger_times >= patience:\n",
    "                print(f'Early stopping at epoch {epoch+1}')\n",
    "                break\n",
    "\n",
    "    print(f'Best Test Accuracy for fold {fold+1}: {best_test_accuracy:.2f}%')\n",
    "    fold_results.append(best_test_accuracy)\n",
    "\n",
    "# Calculate the average and standard deviation of the test accuracies\n",
    "mean_accuracy = np.mean(fold_results)\n",
    "std_accuracy = np.std(fold_results)\n",
    "print(f'Mean Test Accuracy: {mean_accuracy:.2f}%')\n",
    "print(f'Standard Deviation of Test Accuracy: {std_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de366eba-52fc-49df-ac23-3b9e66422f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vmadhu",
   "language": "python",
   "name": "tscproj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
