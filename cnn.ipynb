{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29f28ff8-2840-4484-8174-dd2d7b6993b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 samples from ECG/ECG_TRAIN.ts\n",
      "Loaded 100 samples from ECG/ECG_TEST.ts\n",
      "Fold 1/5\n",
      "Epoch [1/100], Loss: 1.4532, Training Accuracy: 50.62%\n",
      "Test Accuracy after Epoch 1: 70.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vmadhuu\\AppData\\Local\\anaconda3\\envs\\tscproj\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100], Loss: 0.7085, Training Accuracy: 60.62%\n",
      "Test Accuracy after Epoch 2: 70.00%\n",
      "Epoch [3/100], Loss: 0.8181, Training Accuracy: 55.62%\n",
      "Test Accuracy after Epoch 3: 70.00%\n",
      "Epoch [4/100], Loss: 0.7519, Training Accuracy: 63.12%\n",
      "Test Accuracy after Epoch 4: 82.50%\n",
      "Epoch [5/100], Loss: 0.5986, Training Accuracy: 71.25%\n",
      "Test Accuracy after Epoch 5: 75.00%\n",
      "Epoch [6/100], Loss: 0.5453, Training Accuracy: 75.00%\n",
      "Test Accuracy after Epoch 6: 77.50%\n",
      "Epoch [7/100], Loss: 0.5436, Training Accuracy: 73.12%\n",
      "Test Accuracy after Epoch 7: 80.00%\n",
      "Epoch [8/100], Loss: 0.5790, Training Accuracy: 73.75%\n",
      "Test Accuracy after Epoch 8: 77.50%\n",
      "Epoch [9/100], Loss: 0.4887, Training Accuracy: 79.38%\n",
      "Test Accuracy after Epoch 9: 80.00%\n",
      "Epoch [10/100], Loss: 0.4365, Training Accuracy: 79.38%\n",
      "Test Accuracy after Epoch 10: 75.00%\n",
      "Epoch [11/100], Loss: 0.4742, Training Accuracy: 76.88%\n",
      "Test Accuracy after Epoch 11: 72.50%\n",
      "Epoch [12/100], Loss: 0.4261, Training Accuracy: 80.62%\n",
      "Test Accuracy after Epoch 12: 77.50%\n",
      "Epoch [13/100], Loss: 0.4711, Training Accuracy: 73.12%\n",
      "Test Accuracy after Epoch 13: 80.00%\n",
      "Epoch [14/100], Loss: 0.4919, Training Accuracy: 75.62%\n",
      "Test Accuracy after Epoch 14: 77.50%\n",
      "Early stopping at epoch 14\n",
      "Best Test Accuracy for fold 1: 82.50%\n",
      "Fold 2/5\n",
      "Epoch [1/100], Loss: 1.4411, Training Accuracy: 53.75%\n",
      "Test Accuracy after Epoch 1: 55.00%\n",
      "Epoch [2/100], Loss: 0.6280, Training Accuracy: 71.88%\n",
      "Test Accuracy after Epoch 2: 45.00%\n",
      "Epoch [3/100], Loss: 0.5769, Training Accuracy: 68.12%\n",
      "Test Accuracy after Epoch 3: 55.00%\n",
      "Epoch [4/100], Loss: 0.6586, Training Accuracy: 66.88%\n",
      "Test Accuracy after Epoch 4: 57.50%\n",
      "Epoch [5/100], Loss: 0.6572, Training Accuracy: 74.38%\n",
      "Test Accuracy after Epoch 5: 72.50%\n",
      "Epoch [6/100], Loss: 0.6209, Training Accuracy: 66.25%\n",
      "Test Accuracy after Epoch 6: 62.50%\n",
      "Epoch [7/100], Loss: 0.6254, Training Accuracy: 71.88%\n",
      "Test Accuracy after Epoch 7: 50.00%\n",
      "Epoch [8/100], Loss: 0.5920, Training Accuracy: 78.75%\n",
      "Test Accuracy after Epoch 8: 75.00%\n",
      "Epoch [9/100], Loss: 0.5471, Training Accuracy: 79.38%\n",
      "Test Accuracy after Epoch 9: 72.50%\n",
      "Epoch [10/100], Loss: 0.5346, Training Accuracy: 75.00%\n",
      "Test Accuracy after Epoch 10: 70.00%\n",
      "Epoch [11/100], Loss: 0.4834, Training Accuracy: 78.12%\n",
      "Test Accuracy after Epoch 11: 67.50%\n",
      "Epoch [12/100], Loss: 0.4655, Training Accuracy: 80.00%\n",
      "Test Accuracy after Epoch 12: 67.50%\n",
      "Epoch [13/100], Loss: 0.4451, Training Accuracy: 78.75%\n",
      "Test Accuracy after Epoch 13: 72.50%\n",
      "Epoch [14/100], Loss: 0.4768, Training Accuracy: 81.88%\n",
      "Test Accuracy after Epoch 14: 67.50%\n",
      "Epoch [15/100], Loss: 0.5363, Training Accuracy: 75.62%\n",
      "Test Accuracy after Epoch 15: 67.50%\n",
      "Epoch [16/100], Loss: 0.4553, Training Accuracy: 80.00%\n",
      "Test Accuracy after Epoch 16: 77.50%\n",
      "Epoch [17/100], Loss: 0.4535, Training Accuracy: 78.75%\n",
      "Test Accuracy after Epoch 17: 72.50%\n",
      "Epoch [18/100], Loss: 0.4479, Training Accuracy: 76.88%\n",
      "Test Accuracy after Epoch 18: 62.50%\n",
      "Epoch [19/100], Loss: 0.4107, Training Accuracy: 84.38%\n",
      "Test Accuracy after Epoch 19: 75.00%\n",
      "Epoch [20/100], Loss: 0.4304, Training Accuracy: 80.62%\n",
      "Test Accuracy after Epoch 20: 60.00%\n",
      "Epoch [21/100], Loss: 0.4263, Training Accuracy: 83.75%\n",
      "Test Accuracy after Epoch 21: 65.00%\n",
      "Epoch [22/100], Loss: 0.4203, Training Accuracy: 80.00%\n",
      "Test Accuracy after Epoch 22: 70.00%\n",
      "Epoch [23/100], Loss: 0.4730, Training Accuracy: 78.75%\n",
      "Test Accuracy after Epoch 23: 65.00%\n",
      "Epoch [24/100], Loss: 0.4109, Training Accuracy: 78.12%\n",
      "Test Accuracy after Epoch 24: 85.00%\n",
      "Epoch [25/100], Loss: 0.4333, Training Accuracy: 80.62%\n",
      "Test Accuracy after Epoch 25: 55.00%\n",
      "Epoch [26/100], Loss: 0.4207, Training Accuracy: 78.12%\n",
      "Test Accuracy after Epoch 26: 77.50%\n",
      "Epoch [27/100], Loss: 0.4092, Training Accuracy: 82.50%\n",
      "Test Accuracy after Epoch 27: 60.00%\n",
      "Epoch [28/100], Loss: 0.5189, Training Accuracy: 76.88%\n",
      "Test Accuracy after Epoch 28: 75.00%\n",
      "Epoch [29/100], Loss: 0.4118, Training Accuracy: 81.88%\n",
      "Test Accuracy after Epoch 29: 75.00%\n",
      "Epoch [30/100], Loss: 0.3529, Training Accuracy: 84.38%\n",
      "Test Accuracy after Epoch 30: 72.50%\n",
      "Epoch [31/100], Loss: 0.3904, Training Accuracy: 85.00%\n",
      "Test Accuracy after Epoch 31: 62.50%\n",
      "Epoch [32/100], Loss: 0.3665, Training Accuracy: 84.38%\n",
      "Test Accuracy after Epoch 32: 75.00%\n",
      "Epoch [33/100], Loss: 0.3510, Training Accuracy: 86.25%\n",
      "Test Accuracy after Epoch 33: 82.50%\n",
      "Epoch [34/100], Loss: 0.4217, Training Accuracy: 81.88%\n",
      "Test Accuracy after Epoch 34: 67.50%\n",
      "Early stopping at epoch 34\n",
      "Best Test Accuracy for fold 2: 85.00%\n",
      "Fold 3/5\n",
      "Epoch [1/100], Loss: 1.4932, Training Accuracy: 50.00%\n",
      "Test Accuracy after Epoch 1: 62.50%\n",
      "Epoch [2/100], Loss: 0.6613, Training Accuracy: 66.25%\n",
      "Test Accuracy after Epoch 2: 57.50%\n",
      "Epoch [3/100], Loss: 0.6733, Training Accuracy: 66.88%\n",
      "Test Accuracy after Epoch 3: 57.50%\n",
      "Epoch [4/100], Loss: 0.6815, Training Accuracy: 72.50%\n",
      "Test Accuracy after Epoch 4: 72.50%\n",
      "Epoch [5/100], Loss: 0.5324, Training Accuracy: 77.50%\n",
      "Test Accuracy after Epoch 5: 85.00%\n",
      "Epoch [6/100], Loss: 0.5258, Training Accuracy: 76.25%\n",
      "Test Accuracy after Epoch 6: 70.00%\n",
      "Epoch [7/100], Loss: 0.5239, Training Accuracy: 74.38%\n",
      "Test Accuracy after Epoch 7: 80.00%\n",
      "Epoch [8/100], Loss: 0.6301, Training Accuracy: 70.62%\n",
      "Test Accuracy after Epoch 8: 70.00%\n",
      "Epoch [9/100], Loss: 0.5385, Training Accuracy: 75.62%\n",
      "Test Accuracy after Epoch 9: 77.50%\n",
      "Epoch [10/100], Loss: 0.5357, Training Accuracy: 78.75%\n",
      "Test Accuracy after Epoch 10: 82.50%\n",
      "Epoch [11/100], Loss: 0.4833, Training Accuracy: 80.00%\n",
      "Test Accuracy after Epoch 11: 82.50%\n",
      "Epoch [12/100], Loss: 0.4479, Training Accuracy: 76.88%\n",
      "Test Accuracy after Epoch 12: 82.50%\n",
      "Epoch [13/100], Loss: 0.4540, Training Accuracy: 76.88%\n",
      "Test Accuracy after Epoch 13: 75.00%\n",
      "Epoch [14/100], Loss: 0.3883, Training Accuracy: 83.75%\n",
      "Test Accuracy after Epoch 14: 82.50%\n",
      "Epoch [15/100], Loss: 0.4915, Training Accuracy: 76.25%\n",
      "Test Accuracy after Epoch 15: 62.50%\n",
      "Early stopping at epoch 15\n",
      "Best Test Accuracy for fold 3: 85.00%\n",
      "Fold 4/5\n",
      "Epoch [1/100], Loss: 1.4984, Training Accuracy: 44.38%\n",
      "Test Accuracy after Epoch 1: 22.50%\n",
      "Epoch [2/100], Loss: 0.8145, Training Accuracy: 58.75%\n",
      "Test Accuracy after Epoch 2: 22.50%\n",
      "Epoch [3/100], Loss: 0.8102, Training Accuracy: 61.88%\n",
      "Test Accuracy after Epoch 3: 77.50%\n",
      "Epoch [4/100], Loss: 0.8598, Training Accuracy: 58.75%\n",
      "Test Accuracy after Epoch 4: 22.50%\n",
      "Epoch [5/100], Loss: 0.7716, Training Accuracy: 62.50%\n",
      "Test Accuracy after Epoch 5: 80.00%\n",
      "Epoch [6/100], Loss: 0.7018, Training Accuracy: 67.50%\n",
      "Test Accuracy after Epoch 6: 70.00%\n",
      "Epoch [7/100], Loss: 0.6152, Training Accuracy: 74.38%\n",
      "Test Accuracy after Epoch 7: 75.00%\n",
      "Epoch [8/100], Loss: 0.5331, Training Accuracy: 75.00%\n",
      "Test Accuracy after Epoch 8: 60.00%\n",
      "Epoch [9/100], Loss: 0.5296, Training Accuracy: 78.12%\n",
      "Test Accuracy after Epoch 9: 75.00%\n",
      "Epoch [10/100], Loss: 0.5252, Training Accuracy: 76.25%\n",
      "Test Accuracy after Epoch 10: 57.50%\n",
      "Epoch [11/100], Loss: 0.5227, Training Accuracy: 71.25%\n",
      "Test Accuracy after Epoch 11: 80.00%\n",
      "Epoch [12/100], Loss: 0.5028, Training Accuracy: 78.12%\n",
      "Test Accuracy after Epoch 12: 75.00%\n",
      "Epoch [13/100], Loss: 0.5159, Training Accuracy: 74.38%\n",
      "Test Accuracy after Epoch 13: 82.50%\n",
      "Epoch [14/100], Loss: 0.4866, Training Accuracy: 73.75%\n",
      "Test Accuracy after Epoch 14: 67.50%\n",
      "Epoch [15/100], Loss: 0.4835, Training Accuracy: 78.75%\n",
      "Test Accuracy after Epoch 15: 85.00%\n",
      "Epoch [16/100], Loss: 0.5160, Training Accuracy: 78.75%\n",
      "Test Accuracy after Epoch 16: 72.50%\n",
      "Epoch [17/100], Loss: 0.4849, Training Accuracy: 78.75%\n",
      "Test Accuracy after Epoch 17: 87.50%\n",
      "Epoch [18/100], Loss: 0.4657, Training Accuracy: 77.50%\n",
      "Test Accuracy after Epoch 18: 77.50%\n",
      "Epoch [19/100], Loss: 0.4737, Training Accuracy: 80.62%\n",
      "Test Accuracy after Epoch 19: 77.50%\n",
      "Epoch [20/100], Loss: 0.4553, Training Accuracy: 78.12%\n",
      "Test Accuracy after Epoch 20: 80.00%\n",
      "Epoch [21/100], Loss: 0.4464, Training Accuracy: 80.62%\n",
      "Test Accuracy after Epoch 21: 77.50%\n",
      "Epoch [22/100], Loss: 0.4664, Training Accuracy: 80.62%\n",
      "Test Accuracy after Epoch 22: 80.00%\n",
      "Epoch [23/100], Loss: 0.4387, Training Accuracy: 83.12%\n",
      "Test Accuracy after Epoch 23: 80.00%\n",
      "Epoch [24/100], Loss: 0.5024, Training Accuracy: 77.50%\n",
      "Test Accuracy after Epoch 24: 80.00%\n",
      "Epoch [25/100], Loss: 0.5119, Training Accuracy: 78.12%\n",
      "Test Accuracy after Epoch 25: 77.50%\n",
      "Epoch [26/100], Loss: 0.4279, Training Accuracy: 81.88%\n",
      "Test Accuracy after Epoch 26: 90.00%\n",
      "Epoch [27/100], Loss: 0.4400, Training Accuracy: 83.75%\n",
      "Test Accuracy after Epoch 27: 85.00%\n",
      "Epoch [28/100], Loss: 0.4509, Training Accuracy: 81.25%\n",
      "Test Accuracy after Epoch 28: 77.50%\n",
      "Epoch [29/100], Loss: 0.4978, Training Accuracy: 79.38%\n",
      "Test Accuracy after Epoch 29: 87.50%\n",
      "Epoch [30/100], Loss: 0.3864, Training Accuracy: 83.75%\n",
      "Test Accuracy after Epoch 30: 77.50%\n",
      "Epoch [31/100], Loss: 0.4223, Training Accuracy: 78.75%\n",
      "Test Accuracy after Epoch 31: 87.50%\n",
      "Epoch [32/100], Loss: 0.4553, Training Accuracy: 80.00%\n",
      "Test Accuracy after Epoch 32: 75.00%\n",
      "Epoch [33/100], Loss: 0.4658, Training Accuracy: 81.25%\n",
      "Test Accuracy after Epoch 33: 90.00%\n",
      "Epoch [34/100], Loss: 0.4272, Training Accuracy: 80.62%\n",
      "Test Accuracy after Epoch 34: 70.00%\n",
      "Epoch [35/100], Loss: 0.4265, Training Accuracy: 81.88%\n",
      "Test Accuracy after Epoch 35: 90.00%\n",
      "Epoch [36/100], Loss: 0.4061, Training Accuracy: 82.50%\n",
      "Test Accuracy after Epoch 36: 57.50%\n",
      "Early stopping at epoch 36\n",
      "Best Test Accuracy for fold 4: 90.00%\n",
      "Fold 5/5\n",
      "Epoch [1/100], Loss: 1.3375, Training Accuracy: 55.00%\n",
      "Test Accuracy after Epoch 1: 27.50%\n",
      "Epoch [2/100], Loss: 0.7821, Training Accuracy: 61.88%\n",
      "Test Accuracy after Epoch 2: 27.50%\n",
      "Epoch [3/100], Loss: 0.6998, Training Accuracy: 69.38%\n",
      "Test Accuracy after Epoch 3: 55.00%\n",
      "Epoch [4/100], Loss: 0.7357, Training Accuracy: 59.38%\n",
      "Test Accuracy after Epoch 4: 80.00%\n",
      "Epoch [5/100], Loss: 0.6564, Training Accuracy: 67.50%\n",
      "Test Accuracy after Epoch 5: 32.50%\n",
      "Epoch [6/100], Loss: 0.7383, Training Accuracy: 63.75%\n",
      "Test Accuracy after Epoch 6: 77.50%\n",
      "Epoch [7/100], Loss: 0.5630, Training Accuracy: 71.88%\n",
      "Test Accuracy after Epoch 7: 77.50%\n",
      "Epoch [8/100], Loss: 0.5162, Training Accuracy: 72.50%\n",
      "Test Accuracy after Epoch 8: 82.50%\n",
      "Epoch [9/100], Loss: 0.5363, Training Accuracy: 75.00%\n",
      "Test Accuracy after Epoch 9: 75.00%\n",
      "Epoch [10/100], Loss: 0.6201, Training Accuracy: 71.25%\n",
      "Test Accuracy after Epoch 10: 50.00%\n",
      "Epoch [11/100], Loss: 0.5442, Training Accuracy: 76.25%\n",
      "Test Accuracy after Epoch 11: 80.00%\n",
      "Epoch [12/100], Loss: 0.5239, Training Accuracy: 80.62%\n",
      "Test Accuracy after Epoch 12: 77.50%\n",
      "Epoch [13/100], Loss: 0.5239, Training Accuracy: 73.75%\n",
      "Test Accuracy after Epoch 13: 85.00%\n",
      "Epoch [14/100], Loss: 0.5438, Training Accuracy: 76.25%\n",
      "Test Accuracy after Epoch 14: 82.50%\n",
      "Epoch [15/100], Loss: 0.4827, Training Accuracy: 76.88%\n",
      "Test Accuracy after Epoch 15: 80.00%\n",
      "Epoch [16/100], Loss: 0.5023, Training Accuracy: 76.88%\n",
      "Test Accuracy after Epoch 16: 80.00%\n",
      "Epoch [17/100], Loss: 0.4746, Training Accuracy: 80.00%\n",
      "Test Accuracy after Epoch 17: 82.50%\n",
      "Epoch [18/100], Loss: 0.4319, Training Accuracy: 79.38%\n",
      "Test Accuracy after Epoch 18: 75.00%\n",
      "Epoch [19/100], Loss: 0.4351, Training Accuracy: 78.12%\n",
      "Test Accuracy after Epoch 19: 87.50%\n",
      "Epoch [20/100], Loss: 0.4167, Training Accuracy: 82.50%\n",
      "Test Accuracy after Epoch 20: 77.50%\n",
      "Epoch [21/100], Loss: 0.4264, Training Accuracy: 78.75%\n",
      "Test Accuracy after Epoch 21: 80.00%\n",
      "Epoch [22/100], Loss: 0.4168, Training Accuracy: 81.25%\n",
      "Test Accuracy after Epoch 22: 80.00%\n",
      "Epoch [23/100], Loss: 0.4422, Training Accuracy: 79.38%\n",
      "Test Accuracy after Epoch 23: 62.50%\n",
      "Epoch [24/100], Loss: 0.5218, Training Accuracy: 75.62%\n",
      "Test Accuracy after Epoch 24: 80.00%\n",
      "Epoch [25/100], Loss: 0.4801, Training Accuracy: 79.38%\n",
      "Test Accuracy after Epoch 25: 75.00%\n",
      "Epoch [26/100], Loss: 0.4316, Training Accuracy: 82.50%\n",
      "Test Accuracy after Epoch 26: 85.00%\n",
      "Epoch [27/100], Loss: 0.4454, Training Accuracy: 82.50%\n",
      "Test Accuracy after Epoch 27: 80.00%\n",
      "Epoch [28/100], Loss: 0.4338, Training Accuracy: 80.62%\n",
      "Test Accuracy after Epoch 28: 72.50%\n",
      "Epoch [29/100], Loss: 0.4402, Training Accuracy: 84.38%\n",
      "Test Accuracy after Epoch 29: 77.50%\n",
      "Early stopping at epoch 29\n",
      "Best Test Accuracy for fold 5: 87.50%\n",
      "Mean Test Accuracy: 86.00%\n",
      "Standard Deviation of Test Accuracy: 2.55%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "from torchvision import transforms\n",
    "from chart_utils import TimeSeriesImageDataset, accuracy_fn\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Function to read UCR dataset\n",
    "def read_ucr(filename):\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(',')\n",
    "            if len(parts) < 2:\n",
    "                continue\n",
    "            features = [float(f) for f in parts[:-1]]\n",
    "            label = int(parts[-1].split(':')[-1])\n",
    "            data.append(features)\n",
    "            labels.append(label)\n",
    "    \n",
    "    print(f\"Loaded {len(data)} samples from {filename}\")\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "# File paths (adjust these paths as necessary)\n",
    "train_file = 'ECG/ECG_TRAIN.ts'\n",
    "test_file = 'ECG/ECG_TEST.ts'\n",
    "\n",
    "# Load dataset\n",
    "x_train, y_train = read_ucr(train_file)\n",
    "x_test, y_test = read_ucr(test_file)\n",
    "\n",
    "# Normalize labels to be within range [0, num_classes-1]\n",
    "unique_labels = np.unique(y_train)\n",
    "label_map = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "y_train = np.array([label_map[label] for label in y_train])\n",
    "y_test = np.array([label_map[label] for label in y_test])\n",
    "\n",
    "nb_classes = len(unique_labels)\n",
    "\n",
    "# Normalize features\n",
    "x_train_mean = x_train.mean()\n",
    "x_train_std = x_train.std()\n",
    "x_train = (x_train - x_train_mean) / x_train_std\n",
    "x_test = (x_test - x_train_mean) / x_train_std\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(x_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Combine train and test data for K-Fold Cross-Validation\n",
    "X = torch.cat((X_train, X_test))\n",
    "y = torch.cat((y_train, y_test))\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "k_folds = 5\n",
    "kf = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "# Define a simpler CNN Model\n",
    "class Simple2DCNN(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(Simple2DCNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 8, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Conv2d(8, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16 * 16 * 16, 32),  # Adjusted size based on pooling layers\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "# Data Augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # Resize to a smaller size for simpler model\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2)\n",
    "])\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
    "    print(f'Fold {fold+1}/{k_folds}')\n",
    "    \n",
    "    # Create data loaders for the current fold\n",
    "    train_data, test_data = X[train_idx], X[test_idx]\n",
    "    train_labels, test_labels = y[train_idx], y[test_idx]\n",
    "    \n",
    "    train_dataset = TimeSeriesImageDataset(train_data.numpy(), train_labels.numpy(), transform)\n",
    "    test_dataset = TimeSeriesImageDataset(test_data.numpy(), test_labels.numpy(), transform)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    # Initialize the model, criterion, optimizer, and scheduler\n",
    "    model = Simple1DCNN(6, nb_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=0.01)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n",
    "    \n",
    "    num_epochs = 100\n",
    "    best_test_accuracy = 0\n",
    "    patience = 10\n",
    "    trigger_times = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images_area, images_bar, labels in train_loader:\n",
    "            images_area, images_bar, labels = images_area.to(device), images_bar.to(device), labels.to(device)\n",
    "            \n",
    "            # Combine area and bar charts along the channel dimension\n",
    "            combined_images = torch.cat((images_area, images_bar), dim=1)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(combined_images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_accuracy = 100 * correct / total\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Training Accuracy: {epoch_accuracy:.2f}%')\n",
    "\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images_area, images_bar, labels in test_loader:\n",
    "                images_area, images_bar, labels = images_area.to(device), images_bar.to(device), labels.to(device)\n",
    "                \n",
    "                # Combine area and bar charts along the channel dimension\n",
    "                combined_images = torch.cat((images_area, images_bar), dim=1)\n",
    "                \n",
    "                outputs = model(combined_images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        test_accuracy = 100 * correct / total\n",
    "        print(f'Test Accuracy after Epoch {epoch+1}: {test_accuracy:.2f}%')\n",
    "        scheduler.step(epoch_loss)\n",
    "\n",
    "        if test_accuracy > best_test_accuracy:\n",
    "            best_test_accuracy = test_accuracy\n",
    "            trigger_times = 0\n",
    "        else:\n",
    "            trigger_times += 1\n",
    "            if trigger_times >= patience:\n",
    "                print(f'Early stopping at epoch {epoch+1}')\n",
    "                break\n",
    "\n",
    "    print(f'Best Test Accuracy for fold {fold+1}: {best_test_accuracy:.2f}%')\n",
    "    fold_results.append(best_test_accuracy)\n",
    "\n",
    "# Calculate the average and standard deviation of the test accuracies\n",
    "mean_accuracy = np.mean(fold_results)\n",
    "std_accuracy = np.std(fold_results)\n",
    "print(f'Mean Test Accuracy: {mean_accuracy:.2f}%')\n",
    "print(f'Standard Deviation of Test Accuracy: {std_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de366eba-52fc-49df-ac23-3b9e66422f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vmadhu",
   "language": "python",
   "name": "tscproj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
